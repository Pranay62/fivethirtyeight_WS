{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fc6643a-cfaf-4a32-8a14-9ce77ce052c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the topics from below to get details:\n",
      "1. politics\n",
      "2. sports\n",
      "3. science\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter topic:  sports\n",
      "Enter how many pages you want to scrape:  200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Web Scraping Page Number completion status:\n",
      "1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Create an empty list to store the details of the topics\n",
    "topic_details = []\n",
    "\n",
    "# Display the available topics to choose from\n",
    "print(\"Enter the topics from below to get details:\")\n",
    "print(\"1. politics\")\n",
    "print(\"2. sports\")\n",
    "print(\"3. science\")\n",
    "\n",
    "# Prompt the user to enter a topic and convert it to lowercase\n",
    "topic = input('Enter topic: ').lower()\n",
    "\n",
    "# Prompt the user to enter the number of pages to scrape\n",
    "page_number = int(input('Enter how many pages you want to scrape: '))\n",
    "\n",
    "# Display the completion status of scraping each page\n",
    "print('Web Scraping Page Number completion status:')\n",
    "\n",
    "# Iterate over the range of page numbers\n",
    "for i in range(1, page_number + 1):\n",
    "    # Create the URL by replacing the topic and page number in the template URL\n",
    "    url = 'https://fivethirtyeight.com/{}/features/page/{}/'.format(topic, i)\n",
    "    \n",
    "    # Send a GET request to the URL and get the response\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Create a BeautifulSoup object to parse the HTML content\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Find the container element that holds the details of each article\n",
    "    details_elements = soup.find(class_='posts content-area')\n",
    "    \n",
    "    # If no details elements are found, break the loop\n",
    "    if len(details_elements) == 0:\n",
    "        break\n",
    "    else:\n",
    "        # Iterate over each detail element\n",
    "        for element in details_elements.find_all('div', class_='post-info'):\n",
    "            # Extract the necessary information from each element\n",
    "            time = element.find('time', class_='datetime updated').text.strip()\n",
    "            title_element = element.find('h2', class_='article-title entry-title')\n",
    "            title = title_element.text.strip()\n",
    "            title_href = title_element.find('a')['href']\n",
    "            authors = []\n",
    "            author_elements = element.find_all('a', class_='author url fn')\n",
    "            for author_element in author_elements:\n",
    "                authors.append(author_element.text.strip() if author_element else \"\")\n",
    "            authors_str = ', '.join(authors)\n",
    "            author_href = author_element['href']\n",
    "            category_element = element.find('a', class_='term')\n",
    "            category = category_element.text.strip() if category_element else \"\"\n",
    "            category_href = category_element['href'] if category_element else \"\"\n",
    "            \n",
    "            # Append the extracted details to the topic_details list as a dictionary\n",
    "            topic_details.append({\n",
    "                'Date Posted': time,\n",
    "                'Title': title,\n",
    "                'Title Href': title_href,\n",
    "                'Author': authors_str,\n",
    "                'Author Href': author_href,\n",
    "                'Category': category,\n",
    "                'Category Href': category_href\n",
    "            })\n",
    "        \n",
    "        # Display the completion status of scraping the current page\n",
    "        print(i, end=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "568a2b35-ee1c-4f1c-a141-6219062355c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sports_details_200.csv is saved\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date Posted</th>\n",
       "      <th>Title</th>\n",
       "      <th>Title Href</th>\n",
       "      <th>Author</th>\n",
       "      <th>Author Href</th>\n",
       "      <th>Category</th>\n",
       "      <th>Category Href</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apr. 25, 2023</td>\n",
       "      <td>Can Fernando Tatis Jr. Still Mash After A Year...</td>\n",
       "      <td>https://fivethirtyeight.com/features/can-ferna...</td>\n",
       "      <td>Howard Megdal</td>\n",
       "      <td>https://fivethirtyeight.com/contributors/howar...</td>\n",
       "      <td>MLB</td>\n",
       "      <td>https://fivethirtyeight.com/tag/mlb/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apr. 24, 2023</td>\n",
       "      <td>Why Is Anthony Richardson Suddenly The NFL Dra...</td>\n",
       "      <td>https://fivethirtyeight.com/features/anthony-r...</td>\n",
       "      <td>Josh Hermsmeyer</td>\n",
       "      <td>https://fivethirtyeight.com/contributors/josh-...</td>\n",
       "      <td>NFL</td>\n",
       "      <td>https://fivethirtyeight.com/tag/nfl/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apr. 21, 2023</td>\n",
       "      <td>The Bucks Would Be In Big Trouble Without Broo...</td>\n",
       "      <td>https://fivethirtyeight.com/features/the-bucks...</td>\n",
       "      <td>Josh Planos</td>\n",
       "      <td>https://fivethirtyeight.com/contributors/josh-...</td>\n",
       "      <td>NBA Playoffs</td>\n",
       "      <td>https://fivethirtyeight.com/tag/nba-playoffs/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apr. 20, 2023</td>\n",
       "      <td>Busting 4 Major Myths About Referees In The NB...</td>\n",
       "      <td>https://fivethirtyeight.com/features/busting-4...</td>\n",
       "      <td>Ben Dowsett</td>\n",
       "      <td>https://fivethirtyeight.com/contributors/ben-d...</td>\n",
       "      <td>NBA Playoffs</td>\n",
       "      <td>https://fivethirtyeight.com/tag/nba-playoffs/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Apr. 19, 2023</td>\n",
       "      <td>How Mikal Bridges Went From Supporting Player ...</td>\n",
       "      <td>https://fivethirtyeight.com/features/how-mikal...</td>\n",
       "      <td>Jared Dubin</td>\n",
       "      <td>https://fivethirtyeight.com/contributors/jared...</td>\n",
       "      <td>NBA Playoffs</td>\n",
       "      <td>https://fivethirtyeight.com/tag/nba-playoffs/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1857</th>\n",
       "      <td>Feb. 20, 2019</td>\n",
       "      <td>Everything Went Right For The 2018 Red Sox. Ar...</td>\n",
       "      <td>https://fivethirtyeight.com/features/everythin...</td>\n",
       "      <td>Neil Paine</td>\n",
       "      <td>https://fivethirtyeight.com/contributors/neil-...</td>\n",
       "      <td>MLB</td>\n",
       "      <td>https://fivethirtyeight.com/tag/mlb/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858</th>\n",
       "      <td>Feb. 19, 2019</td>\n",
       "      <td>Manny Machadoâ€™s Huge Payday Makes Sense For Th...</td>\n",
       "      <td>https://fivethirtyeight.com/features/manny-mac...</td>\n",
       "      <td>Travis Sawchik</td>\n",
       "      <td>https://fivethirtyeight.com/contributors/travi...</td>\n",
       "      <td>MLB</td>\n",
       "      <td>https://fivethirtyeight.com/tag/mlb/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1859</th>\n",
       "      <td>Feb. 15, 2019</td>\n",
       "      <td>Did The Cubs Miss Their Chance To Be A Dynasty?</td>\n",
       "      <td>https://fivethirtyeight.com/features/did-the-c...</td>\n",
       "      <td>Neil Paine</td>\n",
       "      <td>https://fivethirtyeight.com/contributors/neil-...</td>\n",
       "      <td>MLB</td>\n",
       "      <td>https://fivethirtyeight.com/tag/mlb/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>Feb. 14, 2019</td>\n",
       "      <td>The Thunder Are Paul Georgeâ€™s Team Now</td>\n",
       "      <td>https://fivethirtyeight.com/features/the-thund...</td>\n",
       "      <td>Chris Herring</td>\n",
       "      <td>https://fivethirtyeight.com/contributors/chris...</td>\n",
       "      <td>NBA</td>\n",
       "      <td>https://fivethirtyeight.com/tag/nba/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861</th>\n",
       "      <td>Feb. 14, 2019</td>\n",
       "      <td>Ja Morant Would Like Your Attention</td>\n",
       "      <td>https://fivethirtyeight.com/features/ja-morant...</td>\n",
       "      <td>Josh Planos</td>\n",
       "      <td>https://fivethirtyeight.com/contributors/josh-...</td>\n",
       "      <td>College Basketball</td>\n",
       "      <td>https://fivethirtyeight.com/tag/college-basket...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1862 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date Posted                                              Title  \\\n",
       "0     Apr. 25, 2023  Can Fernando Tatis Jr. Still Mash After A Year...   \n",
       "1     Apr. 24, 2023  Why Is Anthony Richardson Suddenly The NFL Dra...   \n",
       "2     Apr. 21, 2023  The Bucks Would Be In Big Trouble Without Broo...   \n",
       "3     Apr. 20, 2023  Busting 4 Major Myths About Referees In The NB...   \n",
       "4     Apr. 19, 2023  How Mikal Bridges Went From Supporting Player ...   \n",
       "...             ...                                                ...   \n",
       "1857  Feb. 20, 2019  Everything Went Right For The 2018 Red Sox. Ar...   \n",
       "1858  Feb. 19, 2019  Manny Machadoâ€™s Huge Payday Makes Sense For Th...   \n",
       "1859  Feb. 15, 2019    Did The Cubs Miss Their Chance To Be A Dynasty?   \n",
       "1860  Feb. 14, 2019             The Thunder Are Paul Georgeâ€™s Team Now   \n",
       "1861  Feb. 14, 2019                Ja Morant Would Like Your Attention   \n",
       "\n",
       "                                             Title Href           Author  \\\n",
       "0     https://fivethirtyeight.com/features/can-ferna...    Howard Megdal   \n",
       "1     https://fivethirtyeight.com/features/anthony-r...  Josh Hermsmeyer   \n",
       "2     https://fivethirtyeight.com/features/the-bucks...      Josh Planos   \n",
       "3     https://fivethirtyeight.com/features/busting-4...      Ben Dowsett   \n",
       "4     https://fivethirtyeight.com/features/how-mikal...      Jared Dubin   \n",
       "...                                                 ...              ...   \n",
       "1857  https://fivethirtyeight.com/features/everythin...       Neil Paine   \n",
       "1858  https://fivethirtyeight.com/features/manny-mac...   Travis Sawchik   \n",
       "1859  https://fivethirtyeight.com/features/did-the-c...       Neil Paine   \n",
       "1860  https://fivethirtyeight.com/features/the-thund...    Chris Herring   \n",
       "1861  https://fivethirtyeight.com/features/ja-morant...      Josh Planos   \n",
       "\n",
       "                                            Author Href            Category  \\\n",
       "0     https://fivethirtyeight.com/contributors/howar...                 MLB   \n",
       "1     https://fivethirtyeight.com/contributors/josh-...                 NFL   \n",
       "2     https://fivethirtyeight.com/contributors/josh-...        NBA Playoffs   \n",
       "3     https://fivethirtyeight.com/contributors/ben-d...        NBA Playoffs   \n",
       "4     https://fivethirtyeight.com/contributors/jared...        NBA Playoffs   \n",
       "...                                                 ...                 ...   \n",
       "1857  https://fivethirtyeight.com/contributors/neil-...                 MLB   \n",
       "1858  https://fivethirtyeight.com/contributors/travi...                 MLB   \n",
       "1859  https://fivethirtyeight.com/contributors/neil-...                 MLB   \n",
       "1860  https://fivethirtyeight.com/contributors/chris...                 NBA   \n",
       "1861  https://fivethirtyeight.com/contributors/josh-...  College Basketball   \n",
       "\n",
       "                                          Category Href  \n",
       "0                  https://fivethirtyeight.com/tag/mlb/  \n",
       "1                  https://fivethirtyeight.com/tag/nfl/  \n",
       "2         https://fivethirtyeight.com/tag/nba-playoffs/  \n",
       "3         https://fivethirtyeight.com/tag/nba-playoffs/  \n",
       "4         https://fivethirtyeight.com/tag/nba-playoffs/  \n",
       "...                                                 ...  \n",
       "1857               https://fivethirtyeight.com/tag/mlb/  \n",
       "1858               https://fivethirtyeight.com/tag/mlb/  \n",
       "1859               https://fivethirtyeight.com/tag/mlb/  \n",
       "1860               https://fivethirtyeight.com/tag/nba/  \n",
       "1861  https://fivethirtyeight.com/tag/college-basket...  \n",
       "\n",
       "[1862 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create a DataFrame from the team details\n",
    "df = pd.DataFrame(topic_details)\n",
    "\n",
    "# Save the DataFrame as CSV\n",
    "df.to_csv('{}_details_{}.csv'.format(topic,page_number), index=False)\n",
    "print('{}_details_{}.csv'.format(topic,page_number)+' is saved')\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "# Print the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4127bb-f9e9-4de5-89d1-166f9231a74f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
